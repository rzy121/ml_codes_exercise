{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>bk</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   ptratio      bk  lstat  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load data\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "cols = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'bk', 'lstat', 'medv']\n",
    "df = pd.read_csv (url, header=None, names = cols, delim_whitespace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.from_numpy(df.loc[:, ['rm', 'age']].values)\n",
    "y_tensor = torch.from_numpy(df.medv.values ).unsqueeze(1)\n",
    "X_tensor = X_tensor.to(torch.float32)\n",
    "y_tensor = y_tensor.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.4133, -0.1199],\n",
       "        [ 1.0000,  0.1941,  0.3668],\n",
       "        [ 1.0000,  1.2814, -0.2655],\n",
       "        ...,\n",
       "        [ 1.0000,  0.9840,  0.7967],\n",
       "        [ 1.0000,  0.7250,  0.7363],\n",
       "        [ 1.0000, -0.3624,  0.4343]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean = X_tensor.mean(0)\n",
    "X_std = X_tensor.std(0)\n",
    "X_tensor_norm = (X_tensor - X_mean) / X_std\n",
    "X_tensor_norm = torch.cat((torch.ones(X_tensor.shape[0], 1), X_tensor_norm), dim=1)\n",
    "X_tensor_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.rand((3, 1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(X, y, theta):\n",
    "    preds = torch.mm(X, theta)\n",
    "    return ((y - preds)**2).sum() / (2. * X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_iter, X, y, theta, lr=0.01):\n",
    "    for epoch in range(1, n_iter+1):\n",
    "        if theta.grad is not None:\n",
    "            theta.grad.zero_()\n",
    "            \n",
    "        loss = loss_fn(X, y, theta)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            theta -= lr * theta.grad\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Iteration {epoch}, loss = {loss}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, loss = 55.213863372802734\n",
      "Iteration 200, loss = 24.525840759277344\n",
      "Iteration 300, loss = 20.456636428833008\n",
      "Iteration 400, loss = 19.912134170532227\n",
      "Iteration 500, loss = 19.83860969543457\n",
      "Iteration 600, loss = 19.828588485717773\n",
      "Iteration 700, loss = 19.827199935913086\n",
      "Iteration 800, loss = 19.826995849609375\n",
      "Iteration 900, loss = 19.82697296142578\n",
      "Iteration 1000, loss = 19.82697296142578\n",
      "Iteration 1100, loss = 19.82697105407715\n",
      "Iteration 1200, loss = 19.826969146728516\n",
      "Iteration 1300, loss = 19.82696533203125\n",
      "Iteration 1400, loss = 19.82697105407715\n",
      "Iteration 1500, loss = 19.826974868774414\n",
      "Iteration 1600, loss = 19.826974868774414\n",
      "Iteration 1700, loss = 19.826974868774414\n",
      "Iteration 1800, loss = 19.826974868774414\n",
      "Iteration 1900, loss = 19.826974868774414\n",
      "Iteration 2000, loss = 19.826974868774414\n",
      "Iteration 2100, loss = 19.826974868774414\n",
      "Iteration 2200, loss = 19.826974868774414\n",
      "Iteration 2300, loss = 19.826974868774414\n",
      "Iteration 2400, loss = 19.826974868774414\n",
      "Iteration 2500, loss = 19.826974868774414\n",
      "Iteration 2600, loss = 19.826974868774414\n",
      "Iteration 2700, loss = 19.826974868774414\n",
      "Iteration 2800, loss = 19.826974868774414\n",
      "Iteration 2900, loss = 19.826974868774414\n",
      "Iteration 3000, loss = 19.826974868774414\n",
      "Iteration 3100, loss = 19.826974868774414\n",
      "Iteration 3200, loss = 19.826974868774414\n",
      "Iteration 3300, loss = 19.826974868774414\n",
      "Iteration 3400, loss = 19.826974868774414\n",
      "Iteration 3500, loss = 19.826974868774414\n",
      "Iteration 3600, loss = 19.826974868774414\n",
      "Iteration 3700, loss = 19.826974868774414\n",
      "Iteration 3800, loss = 19.826974868774414\n",
      "Iteration 3900, loss = 19.826974868774414\n",
      "Iteration 4000, loss = 19.826974868774414\n",
      "Iteration 4100, loss = 19.826974868774414\n",
      "Iteration 4200, loss = 19.826974868774414\n",
      "Iteration 4300, loss = 19.826974868774414\n",
      "Iteration 4400, loss = 19.826974868774414\n",
      "Iteration 4500, loss = 19.826974868774414\n",
      "Iteration 4600, loss = 19.826974868774414\n",
      "Iteration 4700, loss = 19.826974868774414\n",
      "Iteration 4800, loss = 19.826974868774414\n",
      "Iteration 4900, loss = 19.826974868774414\n",
      "Iteration 5000, loss = 19.826974868774414\n"
     ]
    }
   ],
   "source": [
    "training_loop(5000, X_tensor_norm, y_tensor, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.5327],\n",
       "        [ 5.9031],\n",
       "        [-2.0486]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3910e-05],\n",
       "        [-2.3809e-05],\n",
       "        [-1.1709e-05]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
