{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation Maximization Exercise\n",
    "\n",
    "- The goal is to build a Gaussian Mixture Model (GMM) using EM algorithm\n",
    "- Following example of [this blog](https://zhiyzuo.github.io/EM/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM():\n",
    "    \n",
    "    # constrcutor\n",
    "    def __init__(self, X, k=2):\n",
    "        from scipy.stats import multivariate_normal as mvn\n",
    "        self.mvn = mvn\n",
    "        self.data = X\n",
    "        self.m, self.n = self.data.shape\n",
    "        self.k = k # k = number of latent factors (Gaussian models)\n",
    "    \n",
    "        self.means = np.random.random((self.k, self.n)) # mean vector for the k normals\n",
    "        self.sigmas = np.array([np.eye(self.n) for i in range(self.k)]) # covariance matrix for the k normals\n",
    "        self.phi = np.ones(self.k) / self.k # multi-nomial distribution for k latent-factors. default is 1/k\n",
    "        self.weights = np.ones((self.m, self.k), dtype=float) # weight vector for the data points\n",
    "    \n",
    "    # define log likelihood funciton\n",
    "    # output is the total log-llikelihood across all j models. using iterative calculation to save space\n",
    "    def loglikelihood(self):\n",
    "        loglike = 0\n",
    "        for i in range(self.m):\n",
    "            tmp = 0\n",
    "            for j in range(self.k):\n",
    "                tmp += self.mvn(self.means[j,:], self.sigmas[j, :, :]).pdf(self.data[i, :]) * self.phi[j]\n",
    "            loglike += np.log(tmp)\n",
    "        return loglike\n",
    "    \n",
    "    def e_step(self):\n",
    "        # for each of the j models, calculate the pdf likelihood of each data point under it\n",
    "        # the likelihood is then normalized across all data points, and becomes the weights\n",
    "        for j in range(self.k):\n",
    "            self.weights[:, j] = self.mvn(self.means[j, :], self.sigmas[j, :, :]).pdf(self.data) * self.phi[j]\n",
    "        self.weights = self.weights / self.weights.sum(axis=1).reshape(-1, 1)\n",
    "    \n",
    "    \n",
    "    def m_step(self):\n",
    "        for j in range(self.k):\n",
    "            # update the porbability of j-th model phi[j] to be the mean weights for j-th model\n",
    "            self.phi[j] = self.weights[:, j].mean()\n",
    "            # update the mean vector of the j-th model to be the weighted avg of data\n",
    "            # where weights are likelihood of each data point under the j-th model\n",
    "            self.means[j,:] = self.weights[:, j].T.dot(self.data) / self.weights[:, j].sum()\n",
    "            # similarly, update the covariance matrix of the j-th model\n",
    "            self.sigmas[j, :, :] = (self.weights[:, j].reshape(-1, 1)*(self.data - self.means[j,:])).T.dot(self.weights[:, j].reshape(-1, 1)*(self.data - self.means[j,:]))\n",
    "            self.sigmas[j, :, :] = self.sigmas[j, :, :] / self.weights[:, j].sum()\n",
    "            \n",
    "    # function for training / fitting\n",
    "    def fit(self, tol = 1e-4):\n",
    "        n_iters = 0 # initialize iteration counter\n",
    "        loglike = 1 # initialize log-likelihood\n",
    "        loglike_prev = 0 # previous value of log-likelihood\n",
    "        # while loop for training. stops when the diff between iterations is small enough\n",
    "        while (loglike - loglike_prev > tol):\n",
    "            loglike_prev = self.loglikelihood()\n",
    "            self.e_step() # call expectation step\n",
    "            self.m_step() # call maximization step\n",
    "            n_iters += 1\n",
    "            loglike = self.loglikelihood()  # evaluate new log-likelihood\n",
    "            print(f'iteration {n_iters}: log-likelihood = {loglike}') # log progress\n",
    "        print(f'terminated at {n_iters}-th iteration. log-likelihood = {loglike}')\n",
    "        \n",
    "    def pred_prob(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def pred_label(self):\n",
    "        return self.weights.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate data for testing\n",
    "np.random.seed(614)\n",
    "# 20 data points from Guassian 1\n",
    "X = np.random.multivariate_normal([0, 3], [[0.5, 0], [0, 0.8]], 20)\n",
    "# 50 data points from Gaussian 2\n",
    "X = np.vstack((X, np.random.multivariate_normal([20, 10], np.identity(2), 50)))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1: log-likelihood = -321.53231311258446\n",
      "iteration 2: log-likelihood = -263.3709235830559\n",
      "iteration 3: log-likelihood = -214.28985098622402\n",
      "iteration 4: log-likelihood = -214.28985098622383\n",
      "terminated at 4-th iteration. log-likelihood = -214.28985098622383\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "gmm = GMM(X)\n",
    "gmm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39704838,  3.04389729],\n",
       "       [20.08875246, 10.03920622]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.36977051, -0.13030937],\n",
       "        [-0.13030937,  0.80782007]],\n",
       "\n",
       "       [[ 0.54702472, -0.02641154],\n",
       "        [-0.02641154,  1.06350542]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.pred_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 1.66444484e-160],\n",
       "       [1.00000000e+000, 3.44048537e-158],\n",
       "       [1.00000000e+000, 9.49195082e-169],\n",
       "       [1.00000000e+000, 1.72367559e-165],\n",
       "       [1.00000000e+000, 1.27684644e-165],\n",
       "       [1.00000000e+000, 6.76409215e-184],\n",
       "       [1.00000000e+000, 5.71227682e-167],\n",
       "       [1.00000000e+000, 2.08173793e-161],\n",
       "       [1.00000000e+000, 1.92604390e-161],\n",
       "       [1.00000000e+000, 1.09584884e-151],\n",
       "       [1.00000000e+000, 1.02982340e-161],\n",
       "       [1.00000000e+000, 6.00884706e-150],\n",
       "       [1.00000000e+000, 2.22383290e-161],\n",
       "       [1.00000000e+000, 1.56616931e-179],\n",
       "       [1.00000000e+000, 9.32314945e-177],\n",
       "       [1.00000000e+000, 1.47836166e-167],\n",
       "       [1.00000000e+000, 8.82925131e-181],\n",
       "       [1.00000000e+000, 9.82048859e-171],\n",
       "       [1.00000000e+000, 1.49314182e-181],\n",
       "       [1.00000000e+000, 5.42847809e-170],\n",
       "       [3.87313997e-250, 1.00000000e+000],\n",
       "       [1.96779597e-293, 1.00000000e+000],\n",
       "       [9.74681200e-307, 1.00000000e+000],\n",
       "       [7.28953252e-299, 1.00000000e+000],\n",
       "       [5.94444293e-236, 1.00000000e+000],\n",
       "       [1.67419313e-292, 1.00000000e+000],\n",
       "       [2.71189260e-268, 1.00000000e+000],\n",
       "       [1.06875058e-307, 1.00000000e+000],\n",
       "       [9.42240106e-291, 1.00000000e+000],\n",
       "       [8.59920990e-293, 1.00000000e+000],\n",
       "       [3.05435559e-279, 1.00000000e+000],\n",
       "       [2.43308788e-305, 1.00000000e+000],\n",
       "       [7.06773024e-293, 1.00000000e+000],\n",
       "       [5.86315312e-283, 1.00000000e+000],\n",
       "       [8.39047798e-278, 1.00000000e+000],\n",
       "       [1.74131556e-273, 1.00000000e+000],\n",
       "       [1.49068929e-290, 1.00000000e+000],\n",
       "       [1.06642210e-288, 1.00000000e+000],\n",
       "       [2.42203550e-291, 1.00000000e+000],\n",
       "       [9.04616886e-263, 1.00000000e+000],\n",
       "       [2.91801725e-269, 1.00000000e+000],\n",
       "       [9.23459085e-266, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [2.99048035e-266, 1.00000000e+000],\n",
       "       [8.04280083e-284, 1.00000000e+000],\n",
       "       [3.54441260e-303, 1.00000000e+000],\n",
       "       [1.59682017e-320, 1.00000000e+000],\n",
       "       [2.53456744e-299, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [6.06271580e-296, 1.00000000e+000],\n",
       "       [1.77930070e-307, 1.00000000e+000],\n",
       "       [3.77283056e-268, 1.00000000e+000],\n",
       "       [4.06661945e-316, 1.00000000e+000],\n",
       "       [1.35320112e-288, 1.00000000e+000],\n",
       "       [1.24569160e-278, 1.00000000e+000],\n",
       "       [2.38160711e-271, 1.00000000e+000],\n",
       "       [8.52414204e-246, 1.00000000e+000],\n",
       "       [4.65184371e-272, 1.00000000e+000],\n",
       "       [1.19349622e-280, 1.00000000e+000],\n",
       "       [3.05805133e-274, 1.00000000e+000],\n",
       "       [6.35166446e-294, 1.00000000e+000],\n",
       "       [6.36435991e-242, 1.00000000e+000],\n",
       "       [4.03955657e-263, 1.00000000e+000],\n",
       "       [4.02629859e-308, 1.00000000e+000],\n",
       "       [2.41188822e-263, 1.00000000e+000],\n",
       "       [1.57728638e-266, 1.00000000e+000],\n",
       "       [3.25558972e-280, 1.00000000e+000],\n",
       "       [2.05576748e-276, 1.00000000e+000],\n",
       "       [2.07659511e-299, 1.00000000e+000],\n",
       "       [3.98272428e-273, 1.00000000e+000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.pred_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
